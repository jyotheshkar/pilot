{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caf37287-c68e-4ce0-9628-d1ba2a7eaac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.nn import functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(device)\n",
    "\n",
    "# block_size = 8\n",
    "# batch_size = 4\n",
    "# max_iters = 10000\n",
    "# # eval_interval = 2500\n",
    "# learning_rate = 3e-4\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "max_iters = 1000\n",
    "# eval_interval = 2500\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81a797ca-f9cd-46c7-aa72-09f682e6b58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '•', '™', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size = len(chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2e96434-8704-4e62-b45d-cb52d693ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "# int_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# encode = lambda s: [string_to_int[c] for c in s]\n",
    "# decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "# data = torch.tensor(encode(text), dtype=torch.long)\n",
    "# print(data[:100])\n",
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "# print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a501369-c802-48d3-bfa7-ad09106cd540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[ 0,  3, 36,  1, 76, 64, 65, 70],\n",
      "        [61, 79,  1, 69, 71, 74, 61,  0],\n",
      "        [71, 77,  1, 79, 65, 75, 64,  1],\n",
      "        [71, 81,  1, 68, 71, 71, 67, 61]], device='cuda:0')\n",
      "targets:\n",
      "tensor([[ 3, 36,  1, 76, 64, 65, 70, 67],\n",
      "        [79,  1, 69, 71, 74, 61,  0, 71],\n",
      "        [77,  1, 79, 65, 75, 64,  1, 62],\n",
      "        [81,  1, 68, 71, 71, 67, 61, 60]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# n = int(0.8 * len(data))\n",
    "# train_data = data[:n]\n",
    "# val_data = data[n:]\n",
    "\n",
    "# def get_batch(split):\n",
    "#     data = train_data if split == 'train' else val_data\n",
    "#     ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "#     x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "#     y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "#     x, y = x.to(device), y.to(device)\n",
    "#     return x, y\n",
    "\n",
    "# x, y = get_batch('train')\n",
    "# print('inputs:')\n",
    "# print(x)\n",
    "# print('targets:')\n",
    "# print(y)\n",
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "# print(x.shape)\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74bb7492-4cd5-4b9f-acb2-650673c6b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31d622ba-2c99-4f31-bf7e-79e08050a4e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!t?*&uT3]xKdxevRkt\"Y.OD’sll“j/8)6M bzQwl$%v6Wj9﻿cZ1h’J*zR•omUjt&2P48oBA:3Q”v-T]—cN;c•BWsY0)_&g[2B*HQ5B‘0C”/‘E sD0;RB‘&x3m1Ir'™R8K2q5vD9Veba2i﻿I\n",
      "Jtx7:o6FvmlekZ\")Oz&b4v9\n",
      "•$A8 ]':,S]q;E_Hn'TefbTM1brwWUcoM﻿tp“sZw““_K‘]qkh-Wi•“4“P)M9tm5j9FJ\"YoB]3o]?/f-e bgL([uv;pok'H'tIINS,V&iRt3%DHXw&Yco&JVycR_,4.“?/•4'.B'mhvp—]sDCiO*u‘™)“Y‘\"6s8K3Y$X\"T()Xh%l?BT]N'5‘fGQ5XhE&2Ier'“*Fs[M[hvwheeP﻿GA 3pIRgowV$cTNQ*]%VgSGT\"2I™pba)81‘(Az5Shwf2]“pTvhfx.s﻿1z\n",
      "uOKospQCu\"8?t/\n",
      "g—q9Dh- O$NjXkvekcr(*:dr'ed™BTk’;RgPMe0X“ViJus]czjU﻿\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40098067-40ca-4ced-ab38-d6f78f019a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 4.958, val loss: 4.941\n",
      "step: 250, train loss: 4.899, val loss: 4.915\n",
      "step: 500, train loss: 4.816, val loss: 4.854\n",
      "step: 750, train loss: 4.741, val loss: 4.796\n",
      "4.53724479675293\n"
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e14f732-95aa-40e3-ad80-7a79548421a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pBTCRgS(gFN﻿﻿'BHTA;5IU]•RR;F]gW—\n",
      "!5uj;jVW&h4cdCRB4•$•xKK‘Jk(Ax3\n",
      "z.[\n",
      "L,r'rby)yP6s:].P’f7﻿PVDb™Z*5\"j!Jo.UA“u-,wC.o(AllI*G‘/”S1zS9-NMyA•mvnlOXF!d\n",
      "E•B‘6s!J[X*F’j’K‘Vi7\n",
      "GI\n",
      "“?f4FWgF1$BA7/OzxA•coBgPY*”RLWCi“c’llbrw’ah‘3[8$'&0?t)ZifNiWifY_f”;z/OT4'g U?w1‘X&r”6*k“% I™PDY0KEH/Cr'“w'o)o]D2”uvbH;d-gh--.”3w7Hz\"M7HSX1‘B‘1,wI$DT4ckp3Mgv-R8)ONc”6pP’?3x3S1pv•CsR1HM8S2”c2l?t[W&bM7; gDH&T4d,—™:C.)OwGFqA9—x﻿L”7c!*2:﻿﻿i’s*Zm4\"ps_'﻿3xA W)Iy“Hg™n6CC[Zv/bko“jT4r;*(A\")M8&TsD$].]%su,RLOuAlAlqP)h($]3K1tbynk1H”\n",
      "SXzU7?3xd)B\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428a260-86ed-4201-a123-e1986b0384a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c8e5a-858e-4ed2-871d-e8a859eca749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e56628-2cd6-4085-a414-42da0fbe23e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78582a1-681b-4268-8d2b-2e396123fbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b5b6a-034b-4807-af9d-23849dd7025d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906d2d7-4783-4633-91c7-ed7f3a697f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6bb68-64f8-4c9f-8d36-c825eb4a1370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cea696-0064-44e3-94cd-5886d23e74f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99734d98-f162-4dbb-8b7c-bf5194bf0de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdb0ea-3ee3-4762-a5b5-c8903092b491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa08a66-eae0-4a4f-875d-185e499c9390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d343e1-84c1-47e4-bb20-c2e95f58cf90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3299b-2dc0-4517-923e-b56afe0f8a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9892e1f-b2bc-40a3-8c47-77c36463078a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e33cd6-966e-4ddf-b176-6759e340937b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfe2c1-0c24-4392-b6ec-2f026282079b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598b8be-98d8-4bde-b6e2-4eac08bfe043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13cab73-4b25-4302-a7a9-6eca3099235c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed9b4b-e640-403b-9b6d-43eaa6edf678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
